{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Fake Tweets (*R*)\n",
    "\n",
    "In this notebooks, we will use the \"fake_followers.csv\" data file, from the dataset provided by the Fake Project, as our source data file.\n",
    "\n",
    "## Load the data file\n",
    "\n",
    "> First, we store the file name (*and its location*) in the string '**fileName**'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName0 = 'datasetsFULLcsv/fakeFollowersCSV/tweets.csv'\n",
    "\n",
    "fileNames = c('datasetsFULLcsv/socialSpambots1csv/tweets.csv', 'datasetsFULLcsv/socialSpambots2csv/tweets.csv', 'datasetsFULLcsv/socialSpambots3csv/tweets.csv', 'datasetsFULLcsv/traditionalSpambots1csv/tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the CSV filename previously specified in '**fileName**', we can now load the file into the _data.frame_( ) named '**fakeCSV**'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fakeCSV = read.csv(fileName0)\n",
    "fakeTweets <- data.frame(userID = fakeCSV$user_id, id = fakeCSV$id, text = fakeCSV$text)\n",
    "\n",
    "for (filename in fileNames) {\n",
    "    temp0 = read.csv(filename)\n",
    "    #fakeCSV <- rbind(fakeCSV, temp0)\n",
    "    temp <- data.frame(userID = temp0$user_id, id = temp0$id, text = temp0$text)\n",
    "    fakeTweets <- rbind(fakeTweets, temp)\n",
    "}\n",
    "\n",
    "realCSV = read.csv('datasetsFULLcsv/genuineAccountsCSV/tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the '**fakeCSV**' _data.frame_( ), we will create a smaller, simpler *data.frame*( ) named '**fakeTweets**'.  This reduction in size and complexity of '**fakeTweets**' is due to the fact that it only contains the ID number of the tweet in our database, the ID number of the user who generated the tweet, along with the text of the tweet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fakeTweets <- data.frame(userID = fakeCSV$user_id, id = fakeCSV$id, text = fakeCSV$text)\n",
    "realTweets <- data.frame(userID = realCSV$user_id, id = realCSV$id, text = realCSV$text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we remove web URLS, twitter usernames, twitter hashtags, punctuation, and stand-alone numeric digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove web URLs\n",
    "fakeTweets <- data.frame(userID = fakeTweets$userID, id = fakeTweets$id, text = gsub(\"http[[:alnum:][:punct:]]*\", \"\", fakeTweets$text))\n",
    "realTweets <- data.frame(userID = realTweets$userID, id = realTweets$id, text = gsub(\"http[[:alnum:][:punct:]]*\", \"\", realTweets$text))\n",
    "\n",
    "# remove twitter handles (@<username>)\n",
    "fakeTweets <- data.frame(userID = fakeTweets$userID, id = fakeTweets$id, text = gsub(\"#[[:alnum:][:punct:]]*\", \"\", fakeTweets$text))\n",
    "realTweets <- data.frame(userID = realTweets$userID, id = realTweets$id, text = gsub(\"#[[:alnum:][:punct:]]*\", \"\", realTweets$text))\n",
    "\n",
    "# remove hashtags (#<hashtag name>)\n",
    "fakeTweets <- data.frame(userID = fakeTweets$userID, id = fakeTweets$id, text = gsub(\"@[[:alnum:][:punct:]]*\", \"\", fakeTweets$text))\n",
    "realTweets <- data.frame(userID = realTweets$userID, id = realTweets$id, text = gsub(\"@[[:alnum:][:punct:]]*\", \"\", realTweets$text))\n",
    "\n",
    "# remove punctuation\n",
    "fakeTweets <- data.frame(userID = fakeTweets$userID, id = fakeTweets$id, text = gsub('[[:punct:] ]+', ' ', fakeTweets$text))\n",
    "realTweets <- data.frame(userID = realTweets$userID, id = realTweets$id, text = gsub('[[:punct:] ]+', ' ', realTweets$text))\n",
    "\n",
    "# remove numbers\n",
    "fakeTweets <- data.frame(userID = fakeTweets$userID, id = fakeTweets$id, text = gsub(\"[0-9]\", \"\", fakeTweets$text))\n",
    "realTweets <- data.frame(userID = realTweets$userID, id = realTweets$id, text = gsub(\"[0-9]\", \"\", realTweets$text))\n",
    "\n",
    "# convert to lowercase\n",
    "fakeTweets <- data.frame(userID = fakeTweets$userID, id = fakeTweets$id, text = tolower(fakeTweets$text))\n",
    "realTweets <- data.frame(userID = realTweets$userID, id = realTweets$id, text = tolower(realTweets$text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TidyText the data file\n",
    "\n",
    "> Now we must tokenize the text of each tweet using the '*tidytext*' and '*dplyr*' libraries.  First, we must import the '*tidytext*' and '*dplyr*' libraries,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(tidytext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we convert the data frame of '**fakeTweets**' to the type from the '*dplyr*' library,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fakeTweets <- data_frame(userID = fakeTweets$userID, id = fakeTweets$id, text = as.character(fakeTweets$text))\n",
    "realTweets <- data_frame(userID = realTweets$userID, id = realTweets$id, text = as.character(realTweets$text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> so that we can finally tokenize the text from each of the tweets,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fakeTweetsTOKENS <- fakeTweets %>%\n",
    "    unnest_tokens(word, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realTweetsTOKENS <- realTweets %>%\n",
    "    unnest_tokens(word, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove '*Stop Words*'\n",
    "\n",
    "> Now, we will remove any stop words from the text of the tweets.  To do this, we first import the '*stop_words*' dataset from the '*tidytext*' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, we use the '*anti_join*( )' function from the '*dplyr*' library to remove these stop wrods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeTweetsTOKENS <- fakeTweetsTOKENS %>%\n",
    "    anti_join(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realTweetsTOKENS <- realTweetsTOKENS %>%\n",
    "    anti_join(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrcWORDS <- get_sentiments(\"nrc\")\n",
    "nrcEMOTIONS <- unique(nrcWORDS$sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeTweetsNRCsentiment <- data.frame(id = 0)\n",
    "for (emotion in nrcEMOTIONS){\n",
    "    fakeTweetsNRCsentiment0 <- inner_join(fakeTweetsTOKENS, filter(nrcWORDS, sentiment == emotion))\n",
    "    fakeTweetsNRCsentiment <- full_join(fakeTweetsNRCsentiment, fakeTweetsNRCsentiment0)\n",
    "    }\n",
    "fakeTweetsNRCsentiment <- data.frame(fakeTweetsNRCsentiment[-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realTweetsNRCsentiment <- data.frame(id = as.factor(0))\n",
    "for (emotion in nrcEMOTIONS){\n",
    "    realTweetsNRCsentiment0 <- inner_join(realTweetsTOKENS, filter(nrcWORDS, sentiment == emotion))\n",
    "    realTweetsNRCsentiment <- full_join(realTweetsNRCsentiment, realTweetsNRCsentiment0)\n",
    "    }\n",
    "realTweetsNRCsentiment <- data.frame(realTweetsNRCsentiment[-1,])\n",
    "#realTweetsNRCsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(fakeTweetsNRCsentiment)\n",
    "fakeNRCscoredTweets <- data.frame(table(id, sentiment), realFAKEcat = \"fake\")\n",
    "detach(fakeTweetsNRCsentiment)\n",
    "\n",
    "attach(realTweetsNRCsentiment)\n",
    "realNRCscoredTweets <- data.frame(table(id, sentiment), realFAKEcat = \"real\")\n",
    "detach(realTweetsNRCsentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NRCscoredTweets <- rbind(fakeNRCscoredTweets, realNRCscoredTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(158)\n",
    "fakeTestTrainIND <- sample(1:nrow(fakeNRCscoredTweets), 50000)\n",
    "set.seed(241)\n",
    "realTestTrainIND <- sample(1:nrow(realNRCscoredTweets), 1500000)\n",
    "\n",
    "testNRC <- rbind(fakeNRCscoredTweets[fakeTestTrainIND, ], realNRCscoredTweets[realTestTrainIND, ])\n",
    "trainNRC <- rbind(fakeNRCscoredTweets[-fakeTestTrainIND, ], realNRCscoredTweets[-realTestTrainIND, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nrcSCORES.rf <- randomForest(realFAKEcat ~ .filter(trainNRC, sentiment == \"trust\")$Freq + \n",
    "#                                             filter(trainNRC, sentiment == \"fear\")$Freq +\n",
    " #                                            filter(trainNRC, sentiment == \"negative\")$Freq +\n",
    "  #                                           filter(trainNRC, sentiment == \"sadness\")$Freq + \n",
    "   #                                          filter(trainNRC, sentiment == \"anger\")$Freq + \n",
    "    #                                         filter(trainNRC, sentiment == \"surprise\")$Freq + \n",
    "     #                                        filter(trainNRC, sentiment == \"positive\")$Freq + \n",
    "      #                                       filter(trainNRC, sentiment == \"disgust\")$Freq + \n",
    "       #                                      filter(trainNRC, sentiment == \"joy\")$Freq + \n",
    "        #                                     filter(trainNRC, sentiment == \"anticipation\")$Freq,\n",
    "         #                    data = trainNRC)\n",
    "\n",
    "#nrcSCORES.rf <- randomForest(data.matrix(subset(trainNRC, select = -c(realFAKEcat))), \n",
    "#                              data.matrix(subset(trainNRC, select = c(realFAKEcat))),\n",
    "#                              data.matrix(subset(testNRC, select = -c(realFAKEcat))),\n",
    "#                              data.matrix(subset(testNRC, select = c(realFAKEcat))),\n",
    "#                              ntree = 250000)\n",
    "\n",
    "#nrcSCORES.rf <- randomForest(realFAKEcat ~ sentiment && Freq, data = trainNRC)\n",
    "\n",
    "nrcSCORES.rf <- randomForest(realFAKEcat ~ ., data=trainNRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
